---
title: "Modelo"
author: "Alejandro Brenes, Santiago Fernández, Eyeri Méndez y Erick Venegas"
date: "`r Sys.Date()`"
output: html_document
---

# Preparación inicial

Inicialmente, descargamos las librerías requeridas.

```{r librerias}
pacman::p_load(astsa,
               dplyr,
               ggplot2,
               lubridate,
               MASS,
               paletteer,
               readr,
               statmod,
               tidyr,
               tscount)
```

Posteriormente, se cargan los datos requeridos.

```{r descarga_datos, message = FALSE}
bicicletas <- read_csv("data/bicicletas.csv")
```

Se guarda la paleta de colores utilizada para el desarrollo del proyecto.

```{r paleta_colores}
paleta_colores <- c(
  "#4B1D91",
  "#641896",
  "#84109B",
  "#9B109C",
  "#B0179C",
  "#CB2B97",
  "#E2438A",
  "#EF6276",
  "#F28265",
  "#F2A85F",
  "#EDC375",
  "#E7D39A"
)
```

Algunas correcciones de formato.

```{r formato}
# Se discretiza la variable de días de la semana
bicicletas$weekday <- as.factor(bicicletas$weekday)
levels(bicicletas$weekday) <- c("Dom", "Lun", "Mar", "Mié", "Jue", "Vie", "Sáb")

# Se discretiza la variable del clima
bicicletas$weathersit <- as.factor(bicicletas$weathersit)
levels(bicicletas$weathersit) <- c("Despejado", "Nublado", "Lluvioso/Nevado")

# Se discretiza la variable de la estacion (para boxplot)
bicicletas$season <- as.factor(bicicletas$season)
levels(bicicletas$season) <- c("1", "2", "3", "4")

# Factor para día festivo (0/1 -> No festivo / Festivo)
bicicletas$holiday <- as.factor(bicicletas$holiday)
levels(bicicletas$holiday) <- c("No festivo", "Festivo")

# Factor para día laboral (0/1 -> No laboral / Laboral)
bicicletas$workingday <- as.factor(bicicletas$workingday)
levels(bicicletas$workingday) <- c("No laboral", "Laboral")

# Variable objetivo con lag semanal
bicicletas <- bicicletas %>%
  mutate(lag7 = dplyr::lag(cnt, 7)) %>%
  drop_na()
```

# Desarrollo del modelo

## Ajuste del modelo a través de un GLM

Es esta sección de ajusta el modelo correspondiente, el cual inicia como un GLM. 

Inicialmente, se separan los datos en aquellos de entrenamiento y aquellos de prueba.

```{r separación}
# Datos de entrenamiento, primer año y medio
training <- bicicletas[1:547, ]

# Datos de prueba, los últimos 6 meses registrados
testing <- bicicletas[548:nrow(bicicletas), ]
```

En primer lugar, hay que notar la existencia de sobredispersión, lo cual se puede comprobar en múltiples gráficos del análisis exploratorio, por lo que se usará un modelo de regresión binomial negativa.

Debido a que se puede notar una tendencia creciente, se usará el tiempo como covariable durante el ajuste. Como parece que el clima cambia el conteo de bicicletas, se agrega como covariable. Además, ya que se observa un ciclo semanal evidente en los periodogramas, se agrega el rezago como covariable.

```{r ajuste}
# Lista para guardar los diversos ajustes
lista_ajustes <- list()

# Ajuste del modelo inicial basado en la tendencia de la serie y los periodogramas
lista_ajustes[[1]] <- glm.nb(cnt ~ dteday + lag7, data = training)

# Resumen del ajuste
summary(lista_ajustes[[1]])

# Ya que la estación parece generar cambios en la variable respuesta, se agrega como posible ajuste
lista_ajustes[[2]] <-
  glm.nb(cnt ~ dteday + season + lag7, data = training)

# Resumen del ajuste
summary(lista_ajustes[[2]])

# Parece que el hecho de ser día festivo genera un cambio en la respuesta, por lo que se considera en el siguiente ajuste
lista_ajustes[[3]] <-
  glm.nb(cnt ~ dteday + season + lag7 + holiday, data = training)

# Resumen del ajuste
summary(lista_ajustes[[3]])

# El año también parece afectar al conteo, por lo cual, se hace un ajuste cambiando la última variable
lista_ajustes[[4]] <-
  glm.nb(cnt ~ dteday + season + lag7 + yr, data = training)

# Resumen del ajuste
summary(lista_ajustes[[4]])

# Ajuste con todas las variables consideradas durante el análisis
lista_ajustes[[5]] <-
  glm.nb(cnt ~ dteday + season + lag7 + yr + holiday, data = training)

# Resumen del ajuste
summary(lista_ajustes[[5]])

# Se calcula el AIC y BIC de cada uno de los modelos
(metricas_glm <- data.frame(
  "indice" = 1:5,
  "aic" = sapply(X = lista_ajustes, FUN = AIC),
  "bic" = sapply(X = lista_ajustes, FUN = BIC)
))

# El modelo seleccionado es el segundo, el cual posee el BIC más bajo con las variables con sentido predictivo
ajuste <- lista_ajustes[[2]]
```

## Diagnósticos del ajuste por GLM

### Residuos

Inicialmente, se muestran los residuos de devianza.

```{r residuos}
# Se guardan los residuos de devianza
dev_res <- residuals(ajuste, type = "deviance")

# Se muestran los residuos de devianza
plot(dev_res)

# Se identifican los residuos mayores a 2 (en valor absoluto)
resid_grandes <- sort(abs(dev_res), decreasing = TRUE)[1:sum(abs(dev_res) > 2)]

# Observaciones con grandes residuos
resid_grandes <- training[names(resid_grandes), ]
```

Con respecto a los residuales grandes en valor absoluto, parece que estos son debido a eventos atípicos. Algunos ejemplos de esto:

* 23-3-2012: [Festival](https://link.springer.com/article/10.1007/s13748-013-0040-3) nacional de los cerezos en flor, causó más alquileres de lo normal.
* 26-1-2011 y 27-1-2011: Una fuerte [tormenta de nieve](https://www.washingtontimes.com/news/2011/jan/27/snowstorm-leaves-dc-area-feeling-powerless) afectó diversas áreas de EEUU, incluyendo el área de Washington, en donde se ubica el sistema de bicicletas, lo cual causó menos alquileres de lo normal.
* 6-3-2011: Fue de los días de más humedad registrada, lo cual coincidió con un clima nublado en domingo, lo cual redujo las bicicletas alquiladas, a pesar de ser un día de fin de semana.
* 24-12-2011 y 25-12-2011: Nochebuena y Navidad, lo cual parece haber reducido la cantidad de bicicletas alquiladas.

### Apalancamientos

Seguidamente, se muestran algunos de los apalancamientos más grandes.

```{r apalancamientos}
# Se guardan los apalancamientos
apalancamientos <- hatvalues(ajuste)

# Se identifican las apalancamientos mayores al doble de la media
apal_grandes <-
  sort(apalancamientos, decreasing = TRUE)[1:sum(apalancamientos > 2 * mean(apalancamientos))]

# Observaciones con grandes apalancamientos
apal_grandes <- training[names(apal_grandes), ]

# Cantidad de observaciones con apalancamientos significativamente grandes
nrow(apal_grandes)
```

Hay 10 apalancamientos significativamente grandes (más de 2 veces por encima de la media), esto representa menos del 2% de las observaciones, aunque sigue siendo un elemento a considerar.

### ACF y PACF de residuos

Posteriormente, se muestra el ACF y PACF de los residuos resultantes del modelo GLM binomial negativo.

```{r acf_residuos}
acf2(residuals(ajuste, type = "deviance"), 100, main = "")
```

En el gráfico anterior se observan autocorrelaciones significativas en los residuos de devianza, tanto en el ACF como en el PACF. Esto sugiere que existe una dependencia temporal remanente que el modelo no logra explicar.

La totalidad de los diagnósticos apunta a que existen valores atípicos, apalancamientos considerables y una dependencia temporal en el ajuste de los datos de entrenamiento. Todos estos inconvenientes sugieren que el modelo no parece acoplarse correctamente a los datos disponibles, lo cual invita a considerar otro modelo.

## Ajuste por tsglm

Posteriormente, se prueba el ajuste con un modelo tsglm.

```{r ajuste_glarma}
# Matriz modelo
matrizm <- model.matrix( ~ season + lag7, data = training)

# Ajuste glarma
ajuste_prueba <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 1),
  xreg = matrizm[, -1],
  distr = "nbinom",
  link = "log"
)
```

## Diagnósticos del ajuste por glarma

Se muestran los residuos de Pearson.

```{r residuos_glarma}
plot(residuals(ajuste_prueba, type = "pearson"))
```

Adicionalmente, el ACF y PACF de los residuos restantes.

```{r acfs_glarma}
acf2(residuals(ajuste_prueba, type = "pearson"), 100)
```

