---
title: "Modelo"
author: "Alejandro Brenes, Santiago Fernández, Eyeri Méndez y Erick Venegas"
date: "`r Sys.Date()`"
output: html_document
---

# Preparación inicial

Inicialmente, descargamos las librerías requeridas.

```{r librerias}
pacman::p_load(astsa,
               dplyr,
               ggplot2,
               lubridate,
               MASS,
               paletteer,
               readr,
               statmod,
               tidyr,
               tscount)
```

Posteriormente, se cargan los datos requeridos.

```{r descarga_datos, message = FALSE}
bicicletas <- read_csv("data/bicicletas.csv")
```

Se guarda la paleta de colores utilizada para el desarrollo del proyecto.

```{r paleta_colores}
paleta_colores <- c(
  "#4B1D91",
  "#641896",
  "#84109B",
  "#9B109C",
  "#B0179C",
  "#CB2B97",
  "#E2438A",
  "#EF6276",
  "#F28265",
  "#F2A85F",
  "#EDC375",
  "#E7D39A"
)
```

Algunas correcciones de formato.

```{r formato}
# Se discretiza la variable de días de la semana
bicicletas$weekday <- as.factor(bicicletas$weekday)
levels(bicicletas$weekday) <- c("Dom", "Lun", "Mar", "Mié", "Jue", "Vie", "Sáb")

# Se discretiza la variable del clima
bicicletas$weathersit <- as.factor(bicicletas$weathersit)
levels(bicicletas$weathersit) <- c("Despejado", "Nublado", "Lluvioso/Nevado")

# Se discretiza la variable de la estacion (para boxplot)
bicicletas$season <- as.factor(bicicletas$season)
levels(bicicletas$season) <- c("Invierno", "Primavera", "Verano", "Otoño")

# Factor para día festivo (0/1 -> No festivo / Festivo)
bicicletas$holiday <- as.factor(bicicletas$holiday)
levels(bicicletas$holiday) <- c("No festivo", "Festivo")

# Factor para día laboral (0/1 -> No laboral / Laboral)
bicicletas$workingday <- as.factor(bicicletas$workingday)
levels(bicicletas$workingday) <- c("No laboral", "Laboral")

# Variable objetivo con lag semanal
bicicletas <- bicicletas %>%
  mutate(lag7 = dplyr::lag(cnt, 7)) %>%
  drop_na()
```

# Desarrollo del modelo

## Ajuste del modelo a través de un GLM

Es esta sección de ajusta el modelo correspondiente, el cual inicia como un GLM. 

Inicialmente, se separan los datos en aquellos de entrenamiento y aquellos de prueba.

```{r separación}
# Datos de entrenamiento, primer año y medio
training <- bicicletas[1:540, ]

# Datos de prueba, los últimos 6 meses registrados
testing <- bicicletas[541:nrow(bicicletas), ]
```

En primer lugar, hay que notar la existencia de sobredispersión, lo cual se puede comprobar en múltiples gráficos del análisis exploratorio, por lo que se usará un modelo de regresión binomial negativa.

Debido a que se puede notar una tendencia creciente, se usará el tiempo como covariable durante el ajuste. Como parece que el clima cambia el conteo de bicicletas, se agrega como covariable. Además, ya que se observa un ciclo semanal evidente en los periodogramas, se agrega el rezago como covariable.

```{r ajuste}
# Lista para guardar los diversos ajustes
lista_ajustes <- list()

# Ajuste del modelo inicial basado en la tendencia de la serie y los periodogramas
lista_ajustes[[1]] <- glm.nb(cnt ~ dteday + lag7, data = training)

# Resumen del ajuste
summary(lista_ajustes[[1]])

# Ya que la estación parece generar cambios en la variable respuesta, se agrega como posible ajuste
lista_ajustes[[2]] <-
  glm.nb(cnt ~ dteday + season + lag7, data = training)

# Resumen del ajuste
summary(lista_ajustes[[2]])

# Parece que el hecho de ser día festivo genera un cambio en la respuesta, por lo que se considera en el siguiente ajuste
lista_ajustes[[3]] <-
  glm.nb(cnt ~ dteday + season + lag7 + holiday, data = training)

# Resumen del ajuste
summary(lista_ajustes[[3]])

# El año también parece afectar al conteo, por lo cual, se hace un ajuste cambiando la última variable
lista_ajustes[[4]] <-
  glm.nb(cnt ~ dteday + season + lag7 + yr, data = training)

# Resumen del ajuste
summary(lista_ajustes[[4]])

# Ajuste con todas las variables consideradas durante el análisis
lista_ajustes[[5]] <-
  glm.nb(cnt ~ dteday + season + lag7 + yr + holiday, data = training)

# Resumen del ajuste
summary(lista_ajustes[[5]])

# Se calcula el AIC y BIC de cada uno de los modelos
(metricas_glm <- data.frame(
  "indice" = 1:5,
  "aic" = sapply(X = lista_ajustes, FUN = AIC),
  "bic" = sapply(X = lista_ajustes, FUN = BIC)
))

# El modelo seleccionado es el segundo, el cual posee el BIC más bajo con las variables con sentido predictivo
ajuste <- lista_ajustes[[2]]
```

## Diagnósticos del ajuste por GLM

### Residuos del glm

Inicialmente, se muestran los residuos de devianza.

```{r residuos}
# Se guardan los residuos de devianza
residuos_glm <- residuals(ajuste, type = "pearson")

# Se muestran los residuos de devianza
plot(residuos_glm)

# Se identifican los residuos mayores a 2 (en valor absoluto)
resid_grandes <- sort(abs(residuos_glm), decreasing = TRUE)[1:sum(abs(residuos_glm) > 2)]

# Observaciones con grandes residuos
resid_grandes <- training[names(resid_grandes), ]
```

Con respecto a los residuales grandes en valor absoluto, parece que estos son debido a eventos atípicos. Algunos ejemplos de esto:

* 23-3-2012: [Festival](https://link.springer.com/article/10.1007/s13748-013-0040-3) nacional de los cerezos en flor, causó más alquileres de lo normal.
* 26-1-2011 y 27-1-2011: Una fuerte [tormenta de nieve](https://www.washingtontimes.com/news/2011/jan/27/snowstorm-leaves-dc-area-feeling-powerless) afectó diversas áreas de EEUU, incluyendo el área de Washington, en donde se ubica el sistema de bicicletas, lo cual causó menos alquileres de lo normal.
* 6-3-2011: Fue de los días de más humedad registrada, lo cual coincidió con un clima nublado en domingo, lo cual redujo las bicicletas alquiladas, a pesar de ser un día de fin de semana.
* 24-12-2011 y 25-12-2011: Nochebuena y Navidad, lo cual parece haber reducido la cantidad de bicicletas alquiladas.

### Apalancamientos del glm

Seguidamente, se muestran algunos de los apalancamientos más grandes.

```{r apalancamientos}
# Se guardan los apalancamientos
apalancamientos <- hatvalues(ajuste)

# Se identifican las apalancamientos mayores al doble de la media
apal_grandes <-
  sort(apalancamientos, decreasing = TRUE)[1:sum(apalancamientos > 2 * mean(apalancamientos))]

# Observaciones con grandes apalancamientos
apal_grandes <- training[names(apal_grandes), ]

# Cantidad de observaciones con apalancamientos significativamente grandes
nrow(apal_grandes)
```

Hay 10 apalancamientos significativamente grandes (más de 2 veces por encima de la media), esto representa menos del 2% de las observaciones, aunque sigue siendo un elemento a considerar.

### ACF y PACF de residuos del glm

Posteriormente, se muestra el ACF y PACF de los residuos resultantes del modelo GLM binomial negativo.

```{r acf_residuos}
acf2(residuals(ajuste, type = "pearson"), 100, main = "")
```

En el gráfico anterior se observan autocorrelaciones significativas en los residuos de Pearson, tanto en el ACF como en el PACF. Esto sugiere que existe una dependencia temporal remanente que el modelo no logra explicar.

La totalidad de los diagnósticos apunta a que existen valores atípicos, apalancamientos considerables y una dependencia temporal en el ajuste de los datos de entrenamiento. Todos estos inconvenientes sugieren que el modelo no parece acoplarse correctamente a los datos disponibles, lo cual invita a considerar otro modelo.

## Ajuste por tsglm

Posteriormente, se prueba el ajuste con un modelo tsglm.

```{r ajuste_glarma}
# Lista para guardar los modelos
lista_tsglm <- list()

# Matriz de modelo inicial, con las variables más simples
matrizm <- model.matrix(~ dteday + season, data = training)

# Ajuste tsglm (p = 1, q = 0)
lista_tsglm[[1]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 0),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Ajuste tsglm (p = 1, q = 1)
lista_tsglm[[2]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 1),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Matriz de modelo con la dependencia semanal y la fecha como covariables
matrizm <- model.matrix(~ dteday + lag7, data = training)

# Ajuste tsglm (p = 1, q = 0)
lista_tsglm[[3]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 0),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Ajuste tsglm (p = 1, q = 1)
lista_tsglm[[4]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 1),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Matriz de modelo con la dependencia semanal y la estación como covariables
matrizm <- model.matrix(~ season + lag7, data = training)

# Ajuste tsglm (p = 1, q = 0)
lista_tsglm[[5]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 0),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Ajuste tsglm (p = 1, q = 1)
lista_tsglm[[6]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 1),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Matriz de modelo con la dependencia semanal, la estación y la fecha como covariables
matrizm <- model.matrix(~ dteday + season + lag7, data = training)

# Ajuste tsglm
lista_tsglm[[7]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 0),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Ajuste tsglm
lista_tsglm[[8]] <- tsglm(
  training$cnt,
  model = list(past_obs = 1, past_mean = 1),
  xreg = matrizm[,-1],
  distr = "nbinom",
  link = "log"
)

# Se calculan las diversas métricas para los modelos tsglm
(metricas_tsglm <- data.frame(
  "indice" = 1:8,
  "aic" = sapply(X = lista_tsglm, FUN = AIC),
  "bic" = sapply(X = lista_tsglm, FUN = BIC)
))

# El modelo 6 minimiza el AIC y el BIC, por lo que se mantiene este ajuste
ajuste_tsglm <- lista_tsglm[[6]]

# Resumen del ajuste
summary(ajuste_tsglm)
```

## Diagnósticos del ajuste por tsglm

### Residuos de Pearson del tsglm

Se muestran los residuos de Pearson.

```{r pearson_tsglm}
# Se guardan los residuos de Pearson
residuos_tsglm <- residuals(ajuste_tsglm, type = "pearson")

# Gráfico de los residuos
plot(residuos_tsglm)

# Observaciones con grandes residuos
resid_grandes_tsglm <- training[which(abs(residuos_tsglm) > 2), ]
nrow(resid_grandes_tsglm)
```

Hay más valores atípicos bajo este ajuste que bajo el GLM seleccionado finalmente (21 contra 33). No obstante, parece haber disminuido ligeramente el rango de los residuos en este último modelo (por arriba, principalmente), a pesar de que algunas de las observaciones atípicas se repiten en ambos casos.

### ACF y PACF de residuos del tsglm

Se procede mostrando el ACF y PACF de los residuos de este ajuste.

```{r acf_pacf_tsglm}
# ACF y PACF de los residuos
acf2(residuos_tsglm, 100, main = "")
```

Los gráficos anteriores muestran que los residuos tienen algún componente de autocorrelación remanente, estos mejoran bastante el ajuste por GLM, aunque no parece suficiente para intuir, al menos con esta prueba, que siguen un ruido blanco.

### PIT del tsglm

Se procede con el histograma de la transformación integral de probabilidad (PIT, por sus siglas en inglés).

```{r pit_final}
pit(ajuste_tsglm, main = "")
```

El paper no explica detalladamente cómo interpretar este tipo de datos. Sin embargo, cabe aclarar que no presenta forma de "U" ni de "U inversa", por lo cual, se puede decir que no existe sobredispersión ni infradispersión una vez ajustada la distribución binomial negativa.

## Ajuste final considerando outliers

Para solventar el problema de valores atípicos, se puede ajustar el tsglm para los eventos en donde existen eventos atípicos, esto se hace agregando un peso a las observaciones que muestren este comportamiento. Para este ajuste, se consideran atípicas todas las observaciones con un residual de Pearson mayor a 2.

```{r ajuste_outliers}
# Prueba de hipótesis para comprobar si existen pesos significativos (H0: w0 = ... = ws = 0)
(ajuste_tsglm <- interv_test(ajuste_tsglm, resid_grandes_tsglm$instant - 7, rep(0, 33), est_interv = TRUE))

# Reajustamos el modelo con las observaciones atípicas, pues se rechaza H0
ajuste_tsglm <- ajuste_tsglm$fit_interv

# Resumen del ajujste
summary(ajuste_tsglm)
```

## Diagnósticos del tsglm considerando atípicos

### Criterios de información del tsglm considerando atípicos

Una vez ajustado el nuevo modelo, se procede con algunos diagnósticos como los criterios de información.

```{r criterios_informacion_finales}
# AIC y BIC del modelo final
AIC(ajuste_tsglm)
BIC(ajuste_tsglm)
```

Tanto el AIC como el BIC disminuyeron con el nuevo ajuste, lo que indica que la inclusión de las magnitudes para observaciones atípicas funciona mejor que el modelo sin ellas.

### Residuos de Pearson del tsglm considerando atípicos

Posteriormente los residuos del Pearson del nuevo modelo.

```{r pearson_finales}
# Residuos de pearson
residuos_tsglm <- residuals(ajuste_tsglm, type = "pearson")

# Gráfico de los residuos
plot(residuos_tsglm)

# Observaciones con grandes residuos
resid_grandes_tsglm <- training[which(abs(residuos_tsglm) > 2), ]
nrow(resid_grandes_tsglm)
```

Se redujo la cantidad de observaciones atípicas, de 33 a 24, en comparación al primer ajuste por tsglm. Por otro lado, parece que el rango de residuos se redujo ligeramente por abajo, pero aumentó considerablemente por arriba.

Lo anterior indica que el cambio en el modelo mitigó algunos de los problemas, pero magnifica otros.

### ACF y PACF del tsglm considerando atípicos

Adicionalmente, el ACF y PACF de los residuos restantes.

```{r acfs_tsglm}
acf2(residuals(ajuste_tsglm, type = "pearson"), 100, main = "")
```

Tanto el ACF como el PACF de los residuos de Pearson parece haber empeorado en este ajuste, pues se muestran más valores significativos que en el ajuste anterior. Aunque este sigue siendo bastante mejor que el ajuste por GLM.

### PIT del tsglm considerando atípicos

Se procede con el histograma de la transformación integral de probabilidad.

```{r pit_final}
pit(ajuste_tsglm, main = "")
```

El análisis es análogo al PIT anterior, pues no parece haber un gran cambio.

# Predicción

De los 3 modelos ajustados, se empleará el que utiliza magnitudes para definir los valores atípicos, esto debido a que es el que minimiza las métricas de AIC y BIC.

Una vez elegido el modelo que se usará, se procede a predecir utilizando los datos de prueba, recordando que estos corresponden a los últimos 6 meses del año 2012.

```{r prediccion}
# Semilla para el bootstrap
set.seed(333)

# Matriz de modelo
matrizm <- model.matrix( ~ season + lag7, data = testing)

# Nombres de las columnas restantes
columnas_dif <-
  setdiff(colnames(ajuste_tsglm$xreg), colnames(matrizm))

# Se crea una matriz de 0
matriz_ceros <-
  matrix(0,
         nrow = nrow(matrizm),
         ncol = (ncol(ajuste_tsglm$xreg) - ncol(matrizm[,-1])))

# Se juntan las matrices
matrizm <- cbind(matrizm, matriz_ceros)

# Se cambian los nombres
colnames(matrizm)[2:ncol(matrizm)] <- colnames(ajuste_tsglm$xreg)

# Se elimina la matriz auxiliar
rm(matriz_ceros)

# Predicción de los datos de testing
prediccion <- predict(ajuste_tsglm,
                      n.ahead = nrow(matrizm),
                      newxreg = matrizm[,-1],
                      B = 10000)
```

# Resultados

Con la predicción obtenida, a continuación se muestran los resultados a través de un gráfico comparativo y diversos diagnósticos.

Se inicia con un gráfico comparativo que muestra la predicción y los valores reales.

```{r grafico_comparativo}
# Se agregan los datos a un dataframe y se grafican
data.frame(
  "fecha" = testing$dteday,
  "real" = testing$cnt,
  "prediccion" = prediccion$pred,
  "ic_inferior" = prediccion$interval[, "lower"],
  "ic_superior" = prediccion$interval[, "upper"]
) %>%
  ggplot(aes(x = fecha)) +
  geom_line(aes(y = real, color = "Real")) +
  geom_line(aes(y = prediccion, color = "Predicción")) +
  geom_ribbon(aes(ymin = ic_inferior, ymax = ic_superior, fill = "IC predicción"),
              alpha = 0.1) +
  scale_color_manual(name = "Series", values = c("Real" = paleta_colores[1], "Predicción" = paleta_colores[4])) +
  scale_fill_manual(name = "IC", values = c("IC predicción" = paleta_colores[6])) +
  labs(x = "Fecha (2012)", y = "Cantidad de bicicletas") +
  theme_minimal()
```

Se observa que, aunque la estimación parece correcta en algunos puntos, existe una incertidumbre inmensa con el modelo seleccionado. Se observan valores atípicos claros, que incluso llegan a salir del IC, pero el comportamiento general indica que hay un gran error en la estimación.

A continuación, se muestra el error que hubo en cada observación a través de un residuo crudo, este corresponde a la resta del valor real con el estimado.

```{r residuos_crudos}
# Residuos
resid_final <- testing$cnt - prediccion$pred

# Gráfico de residuos
data.frame("fecha" = testing$dteday,
           "error" = resid_final) %>% 
  ggplot(aes(x = fecha, y = error)) +
  geom_point(color = paleta_colores[3]) +
  labs(x = "Fecha (2012)", y = "Error") +
  theme_minimal()

# Cantidad de residuos mayores a 100 en valor absoluto (porcentaje)
sum(abs(resid_final) > 100) / length(resid_final)

# Cantidad de residuos mayores a 1000 en valor absoluto (porcentaje)
sum(abs(resid_final) > 1000) / length(resid_final)
```

Los mayores errores se observan debido al [Huracán Sandy](https://www.bbc.com/mundo/noticias/2012/10/121029_livetext_supertormenta_sandy_ao), el cual supuso una gran catástrofe en EEUU y, por supuesto, impedía que las personas utilizaran el servicio.

Sin embargo, a pesar del evento atípico mencionado, se observa que casi todas las predicciones difieren en más de 100 bicicletas (95.1\%). De igual forma, existe una gran cantidad de observaciones que poseen una distancia mayor a 1000 bicicletas (41.8\%).

Todos estos factores hacen imposible decir que la predicción del modelo fue acertada, la elevada incertidumbre combinada con un valor medio con gran error respecto a los datos reales evidencian que el desempeño del modelo no fue el esperado.